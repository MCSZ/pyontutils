{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect, Table, Column\n",
    "import urllib\n",
    "import requests \n",
    "from pyontutils.utils import * \n",
    "from pyontutils.core import *\n",
    "import rdflib\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import sys\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_ilx = makeGraph('', graph=rdflib.Graph().parse('../Interlex.ttl', format='turtle'))\n",
    "g_ilxqnames = makeGraph('', graph=rdflib.Graph().parse('../Interlex.ttl', format='turtle'))\n",
    "#g_nif = makeGraph('', graph=rdflib.Graph().parse('../NIF-ALL.ttl', format='turtle'))\n",
    "g_nif = makeGraph('', graph=pickle.load(open('../NIF-ALL.pickle', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "break\n",
    "curr_stage = 'production'\n",
    "\n",
    "if curr_stage == 'beta':\n",
    "    engine_key = 'mysql+mysqlconnector://nif_eelg_secure:5Aruchug@dudley.crbs.ucsd.edu:3306/nif_eelg' #beta\n",
    "elif curr_stage == 'production':\n",
    "    engine_key = 'mysql+mysqlconnector://nif_eelg_secure:5Aruchug@nif-mysql.crbs.ucsd.edu:3306/nif_eelg' #production\n",
    "\n",
    "def get_df(engine_key):\n",
    "    engine = create_engine(engine_key)\n",
    "    data =  \"\"\"\n",
    "            SELECT ti.iri, t.ilx\n",
    "            FROM term_existing_ids AS ti\n",
    "            JOIN terms AS t\n",
    "            WHERE ti.tid = t.id\n",
    "            AND t.type != 'cde'\n",
    "            \"\"\"\n",
    "    return pd.read_sql(data, engine)\n",
    "df = get_df(engine_key) \n",
    "iri_to_ilx = {str(row.iri):str(row.ilx) for row in df.itertuples() if row.iri}\n",
    "iri_to_family_iris = {}\n",
    "for i, row in df.iterrows():\n",
    "    if row.iri:\n",
    "        iri_to_family_iris.update({row.iri:list(df.loc[df.ilx == iri_to_ilx[row.iri], 'iri'])})\n",
    "outf = '/Users/tmsincomb/Desktop/interlexutils/ontology-interlex/dump/iri-to-family.json'\n",
    "with open(outf, 'w') as outfile:\n",
    "    json.dump(iri_to_family_iris, outfile, indent=4)\n",
    "outf = '/Users/tmsincomb/Desktop/interlexutils/ontology-interlex/dump/iri-to-ilx.json'\n",
    "with open(outf, 'w') as outfile:\n",
    "    json.dump(iri_to_ilx, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iri_to_family_iris = json.load(open('/Users/tmsincomb/Desktop/interlexutils/ontology-interlex/dump/iri-to-family.json','r'))\n",
    "iri_to_ilx = json.load(open('/Users/tmsincomb/Desktop/interlexutils/ontology-interlex/dump/iri-to-ilx.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subjs(graph):\n",
    "    subjs = set()\n",
    "    for s, p, o in graph.g.triples((None, None, None)):\n",
    "        #graph.g.subjects(rdflib.RDF.type, rdflib.OWL.Class) #for future ref\n",
    "        if isinstance(s, rdflib.URIRef):\n",
    "            subjs.add(s)\n",
    "        if isinstance(p, rdflib.URIRef):\n",
    "            subjs.add(p)\n",
    "        if isinstance(o, rdflib.URIRef):\n",
    "            subjs.add(o)\n",
    "        \n",
    "    return subjs\n",
    "\n",
    "ilx_subjs = get_subjs(g_ilx)\n",
    "nif_subjs = get_subjs(g_nif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Delete all Defaults \"\"\"\n",
    "ns_to_del = []\n",
    "for namespace in g_nif.namespaces:\n",
    "    if 'default' in namespace.split(':')[0]:\n",
    "        ns_to_del.append(namespace)\n",
    "for ns in ns_to_del:\n",
    "    g_nif.del_namespace(ns)\n",
    "    \n",
    "\"\"\" Create new namespaces; old are messed up \"\"\"\n",
    "for s, ns in g_nif.namespaces.items():\n",
    "    g_nif.del_namespace(s)\n",
    "    g_nif.add_namespace(s, rdflib.Namespace(str(ns)))\n",
    "\n",
    "\"\"\" Reset blasted cache \"\"\"\n",
    "for _ in range(10):\n",
    "    g_nif.g.namespace_manager.reset()\n",
    "    \n",
    "\"\"\" Fill ilx qname to fix the existing ids \"\"\"\n",
    "for s, ns in g_nif.namespaces.items():\n",
    "    if not g_ilxqnames.namespaces.get(s):\n",
    "        g_ilxqnames.add_namespace(s, rdflib.Namespace(str(ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformat_graph_to_dict(graph, subjs):\n",
    "    \n",
    "    total_data = {}\n",
    "\n",
    "    for subj in subjs:\n",
    "        \n",
    "        data = defaultdict(list)\n",
    "        \n",
    "        for pred, o in graph.g.predicate_objects(subject=subj):\n",
    "            \n",
    "            pqname = graph.qname(pred)\n",
    "            data[pqname].append(str(o))\n",
    "\n",
    "        total_data.update({str(subj):data})\n",
    "    \n",
    "    return total_data\n",
    "    \n",
    "tempINTERLEX = reformat_graph_to_dict(graph=g_ilx, subjs=ilx_subjs)\n",
    "NIF = reformat_graph_to_dict(graph=g_nif, subjs=nif_subjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://neurolex.org/wiki/nifext_5177': defaultdict(list,\n",
       "             {'ilxtr:existingIds': ['http://uri.interlex.org/base/ilx_0111727',\n",
       "               'http://neurolex.org/wiki/nifext_5177',\n",
       "               'http://uri.neuinfo.org/nif/nifstd/nifext_5177'],\n",
       "              'rdf:type': ['http://www.w3.org/2002/07/owl#Class'],\n",
       "              'rdfs:label': ['Thromboxane'],\n",
       "              'rdfs:subClassOf': ['http://uri.interlex.org/base/ilx_0109444']}),\n",
       " 'http://uri.neuinfo.org/nif/nifstd/nifext_5177': defaultdict(list,\n",
       "             {'ilxtr:existingIds': ['http://uri.interlex.org/base/ilx_0111727',\n",
       "               'http://neurolex.org/wiki/nifext_5177',\n",
       "               'http://uri.neuinfo.org/nif/nifstd/nifext_5177'],\n",
       "              'rdf:type': ['http://www.w3.org/2002/07/owl#Class'],\n",
       "              'rdfs:label': ['Thromboxane'],\n",
       "              'rdfs:subClassOf': ['http://uri.interlex.org/base/ilx_0109444']})}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INTERLEX = {}\n",
    "for key, pred_dict in tempINTERLEX.items():\n",
    "             \n",
    "    if '/ilx' in key:\n",
    "        ilx_id = key\n",
    "    else: continue\n",
    "\n",
    "    data = {}\n",
    "    for iri in pred_dict['ilxtr:existingIds']:\n",
    "        if iri == key: continue\n",
    "        data.update({str(iri):pred_dict})\n",
    "    \n",
    "    INTERLEX.update({ilx_id:data})\n",
    "#'ILX:0106837'\n",
    "INTERLEX[list(INTERLEX)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edge_cases = {\n",
    "    #Definitions\n",
    "    'definition:' : 'definition:',\n",
    "    \n",
    "    #ExistingIds\n",
    "    'ilxtr:existingIds' : 'ilxtr:existingIds',\n",
    "    \n",
    "    #LABELS\n",
    "    'rdfs:label' : 'rdfs:label',\n",
    "    \n",
    "    #SUPERCLASSES\n",
    "    'rdfs:subClassOf' : 'rdfs:subClassOf',\n",
    "    \n",
    "    #SYNONYMS\n",
    "    'oboInOwl:hasExactSynonym' : 'NIFRID:synonym',\n",
    "    'oboInOwl:hasNarrowSynonym' : 'NIFRID:synonym',\n",
    "    'oboInOwl:hasBroadSynonym' : 'NIFRID:synonym',\n",
    "    'oboInOwl:hasRelatedSynonym' : 'NIFRID:synonym',\n",
    "    'go:systematic_synonym' : 'NIFRID:synonym',\n",
    "    'NIFRID:synonym' : 'NIFRID:synonym',\n",
    "    \n",
    "    #TYPE\n",
    "    'rdf:type':'rdf:type',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ilx = INTERLEX['http://uri.interlex.org/base/ilx_0106569']['http://purl.obolibrary.org/obo/UBERON_0027368']\n",
    "ilxdf = pd.DataFrame(dict([(edge_cases[k],pd.Series(v)) for k,v in ilx.items() if edge_cases.get(k)]))\n",
    "ilxdf = ilxdf.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The larger of two chemoarchitectural compartments identified in the neostriatum through differential staining for various biochemical markers.  It usually is identified through differentially high staining for acetylcholinesterase and calbinin D28K.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ilxdf.definition[ilxdf['definition'] != False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compare_lists(list_1, list_2, i, n, b, key, visited):\n",
    "    if list_1:\n",
    "        list1 = [v.lower().strip() for v in list_1]\n",
    "        i_real_value = {v.lower().strip():v for v in list_1}\n",
    "    else:\n",
    "        n.update({key:[v for v in list_2 if v]})\n",
    "        return i, n, b, visited\n",
    "    if list_2:\n",
    "        list2 = [v.lower().strip() for v in list_2]\n",
    "        n_real_value = {v.lower().strip():v for v in list_2}\n",
    "    else:\n",
    "        i.update({edge_cases[key]:[v for v in list_1 if v]})\n",
    "        return i, n, b, visited\n",
    "    \n",
    "    if set(list1) - set(list2):\n",
    "        i.update({edge_cases[key]:[i_real_value[v] for v in list(set(list1) - set(list2)) if v]})\n",
    "    if set(list2) - set(list1):\n",
    "        n.update({key:[n_real_value[v] for v in list(set(list2) - set(list1)) if v]})\n",
    "    if set(list2) & set(list1):\n",
    "        b.update({key:[n_real_value[v] for v in list(set(list1) & set(list2)) if v]})\n",
    "        #for v in list(set(list1) & set(list2)):\n",
    "        #    print({key:n_real_value[v]})\n",
    "        #    if not visited.get((edge_cases[key],v)):\n",
    "        #        b.update({key:n_real_value[v]})\n",
    "        #        visited[(edge_cases[key], v)]=True                \n",
    "    return i, n, b, visited\n",
    "#b.update({key:[n_real_value[v] for v in list(set(list1) & set(list2)) if v]})\n",
    "\n",
    "hits=set()\n",
    "data = defaultdict(dict)\n",
    "\n",
    "for ilx_id in INTERLEX.keys():\n",
    "    \n",
    "    #if ilx_id != 'http://uri.interlex.org/base/ilx_0110011': continue\n",
    "    \n",
    "    for iri, pred_dict in INTERLEX[ilx_id].items():\n",
    "        \n",
    "        #if '93816' not in iri: continue\n",
    "            \n",
    "        nif = NIF.get(iri)\n",
    "        ilx = pred_dict\n",
    "\n",
    "        if nif: #if iri exists in nif\n",
    "            \n",
    "            both_keys = set(nif) | set(ilx)\n",
    "            i, n, b, visited = {}, {}, {}, {}\n",
    "            \n",
    "            for k in both_keys:\n",
    "                \n",
    "                if edge_cases.get(k): #if key equals something in ilx\n",
    "                    \n",
    "                    ilx_values = ilx[edge_cases[k]]\n",
    "                    nif_values = nif[k]\n",
    "                    \n",
    "                    if edge_cases.get(k) == 'rdfs:subClassOf' and ilx.get('rdfs:subClassOf'): #needs special traversal up the graph\n",
    "                        ilx_sc_iris = iri_to_family_iris[ilx_values[0]]\n",
    "                        i, n, b, visited = compare_lists(ilx_sc_iris, nif_values, i, n, b, k, visited)\n",
    "                        \n",
    "                    else:\n",
    "                        i, n, b, visited = compare_lists(ilx_values, nif_values, i, n, b, k, visited)\n",
    "                        \n",
    "                else: \n",
    "                    n.update({k:[v for v in nif[k] if v]})\n",
    "        \n",
    "            \n",
    "            data[g_ilxqnames.qname(ilx_id)].update({\n",
    "                g_ilxqnames.qname(iri): {\n",
    "                    'ilx-only'     : sorted([(k,g_ilxqnames.qname(v)) for k,vs in i.items() for v in vs]),\n",
    "                    'nif-only'     : sorted([(k,g_ilxqnames.qname(v)) for k,vs in n.items() for v in vs]),\n",
    "                    'both-contain' : sorted([(k,g_ilxqnames.qname(v)) for k,vs in b.items() for v in vs]),\n",
    "                }\n",
    "            })\n",
    "\n",
    "            \n",
    "outf = '/Users/tmsincomb/Desktop/interlexutils/ontology-interlex/dump/moderate-nif-ilx-comparator-from-pickle.json'\n",
    "with open(outf, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4)\n",
    "    \n",
    "#ex for short hand vi -e \n",
    "#-s so it doesnt open the file\n",
    "#-cwq is command-save-quit\n",
    "#use $ to specify variable\n",
    "!ex -s +'g/\\[[\\ \\n]\\+\"/j4' -cwq $outf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 out of 2000 for protein\n",
      "450 out of 2000 for fat\n",
      "910 out of 2000 for carbs\n"
     ]
    }
   ],
   "source": [
    "total_cals = 2000\n",
    "protein = 160\n",
    "fat = 50\n",
    "\n",
    "print(160*4,'out of', total_cals, 'for protein')\n",
    "print(50*9,'out of', total_cals, 'for fat')\n",
    "print(total_cals - 160*4 - 50*9,'out of', total_cals, 'for carbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "75 + "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
