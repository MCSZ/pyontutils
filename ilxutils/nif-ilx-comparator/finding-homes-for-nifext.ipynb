{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Quality.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-Morphology-Inferred.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Molecule-Role-Bridge.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-BrainRegion-Bridge.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-NT-Bridge-Inferred.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-Circuit-Role-Bridge.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-GrossAnatomy.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-Morphology-Bridge.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-BR-Inferred.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Molecule-Role-Inferred.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Molecule.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Chemical.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-NT-Bridge.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-MolecularConstituent-Inferred.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/BIRNLex-OBO-UBO.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-MolecularConstituent-Bridge.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Neuron-Circuit-Role-Inferred.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Subcellular.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-PRO-Bridge.ttl\n",
      "/Users/tmsincomb/Desktop/work/NIF-Ontology/ttl/NIF-Cell.ttl\n",
      "10256\n",
      "5128\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "4429\n",
      "501\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect, Table, Column\n",
    "import urllib\n",
    "import requests \n",
    "from pyontutils.utils import rdf, rdfs, owl, skos, oboInOwl, makeGraph, makePrefixes\n",
    "import rdflib\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "#name = urllib.parse.quote(str(row.label))\n",
    "#link = 'https://scicrunch.org/scicrunch/interlex/view/' + str(row.ilx) + '?searchTerm=' + name\n",
    "#data.append({'curie':row.curie, 'iri':row.iri, 'link':link})\n",
    "\n",
    "#engine_key = 'mysql+mysqlconnector://nif_eelg_secure:5Aruchug@dudley.crbs.ucsd.edu:3306/nif_eelg' #beta\n",
    "engine_key = 'mysql+mysqlconnector://nif_eelg_secure:5Aruchug@nif-mysql.crbs.ucsd.edu:3306/nif_eelg' #production\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_terms(engine_key):\n",
    "    engine = create_engine(engine_key)\n",
    "    data =  \"\"\"\n",
    "            SELECT ti.curie, t.label, ti.tid, ti.iri, t.ilx, t.type\n",
    "            FROM term_existing_ids AS ti\n",
    "            JOIN terms AS t\n",
    "            WHERE ti.tid = t.id\n",
    "            AND t.type != 'cde'\n",
    "            \"\"\"\n",
    "    df = pd.read_sql(data, engine)\n",
    "    return df\n",
    "\n",
    "df = get_terms(engine_key=engine_key)\n",
    "iri_tid = {str(row.iri):int(row.tid) for row in df.itertuples() if row.iri}\n",
    "label_tid = {str(row.label).lower():int(row.tid) for row in df.itertuples() if row.label}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nifext= ['NIF-Quality.ttl', 'NIF-Neuron-Morphology-Inferred.ttl', 'NIF-Molecule-Role-Bridge.ttl', 'NIF-Neuron-BrainRegion-Bridge.ttl', 'NIF-Neuron-NT-Bridge-Inferred.ttl', 'NIF-Neuron-Circuit-Role-Bridge.ttl', 'NIF-GrossAnatomy.ttl', 'NIF-Neuron-Morphology-Bridge.ttl', 'NIF-Neuron-BR-Inferred.ttl', 'NIF-Molecule-Role-Inferred.ttl', 'NIF-Molecule.ttl', 'NIF-Chemical.ttl', 'NIF-Neuron-NT-Bridge.ttl', 'NIF-Neuron-MolecularConstituent-Inferred.ttl', 'BIRNLex-OBO-UBO.ttl', 'NIF-Neuron-MolecularConstituent-Bridge.ttl', 'NIF-Neuron-Circuit-Role-Inferred.ttl', 'NIF-Subcellular.ttl', 'NIF-PRO-Bridge.ttl', 'NIF-Cell.ttl', 'NIF-NIFSTD-mapping.ttl', 'NIF-Neuron-HBP-cell-import.ttl', 'ksdesc-defs.ttl', 'chebi-bridge.ttl', 'chemical-bridge.ttl', 'NIF-GrossAnatomy-Inferred.ttl', 'uberon-bridge-to-nifstd.ttl', 'NIF-Neuron-Quality-Bridge.ttl', 'NIF-Neuron-SomaLocation-Bridge.ttl']\n",
    "graph = rdflib.Graph()\n",
    "for f in glob('/Users/tmsincomb/Desktop/work/NIF-Ontology/'+'*/*.ttl') + glob('*.ttl'):\n",
    "    if f.rsplit('/',1)[-1] in nifext:\n",
    "        print(f)\n",
    "        graph.parse(f, format='turtle')\n",
    "\n",
    "mg = makeGraph('nifall', makePrefixes('NIFTTL', 'owl', 'skos'), graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10256\n"
     ]
    }
   ],
   "source": [
    "def append_current_nifext(duplicates, label, uri):\n",
    "    seg_df = df.loc[df.label.str.lower() == label.lower()]\n",
    "    for row in seg_df.itertuples():\n",
    "        if 'nifext' in row.iri.lower():\n",
    "             duplicates[uri].append(row.iri)\n",
    "    return duplicates\n",
    "\n",
    "import pickle\n",
    "inputfile = '/Users/tmsincomb/Desktop/dump/NIF-Interlex-comparison-files/all-uri.neuinfo.org-uris.pickle'\n",
    "NIF = pickle.load(open(inputfile, 'rb'))\n",
    "print(len(NIF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5128\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "4429 977\n",
      "756\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2e1f7f13cfd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mactually_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mduplicates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'existing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mactually_found\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactually_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "lost_iris = []\n",
    "for uri in NIF:\n",
    "    if not iri_tid.get(str(uri)):\n",
    "        lost_iris.append(uri)\n",
    "print(len(lost_iris))\n",
    "\n",
    "duplicates = defaultdict(list)\n",
    "actually_found = {}\n",
    "count = 0\n",
    "found = 0\n",
    "for i, uri in enumerate(lost_iris):\n",
    "    if i % 1000 == 0: print(i)\n",
    "    if isinstance(uri, rdflib.URIRef):\n",
    "        short_s = mg.qname(uri)\n",
    "    \n",
    "        url = 'http://scigraph.olympiangods.org/scigraph/vocabulary/id/'+urllib.parse.quote(short_s)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code not in [200, 201]: continue\n",
    "        else: response = requests.get(url).json()   \n",
    "        labels = [label.lower() for label in response['labels']]\n",
    "        if labels:\n",
    "            count += 1\n",
    "            \n",
    "        def found_existence(label):\n",
    "            if label_tid.get(label):\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        for label in labels:\n",
    "            if found_existence(label):\n",
    "                found += 1\n",
    "                duplicates = append_current_nifext(duplicates, label, uri) #finished off the dict\n",
    "                visited[label]=True\n",
    "                \n",
    "print(count, found)\n",
    "                \n",
    "with open('/Users/tmsincomb/Desktop/dump/nifext-duplicates-and-new.json', 'w') as outfile:\n",
    "    json.dump(duplicates, outfile, indent=4)\n",
    "    \n",
    "print(len(duplicates.keys()))\n",
    "actually_found = []\n",
    "for key, values in duplicates.items():\n",
    "    if not values['existing']:\n",
    "        actually_found.append(key)\n",
    "print(len(actually_found))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
