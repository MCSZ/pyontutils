{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyontutils.utils import * \n",
    "from pyontutils.core import *\n",
    "from pyontutils.closed_namespaces import *\n",
    "import rdflib\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iri_to_family_iris = json.load(open('/home/troy/Desktop/interlexutils/nif-ilx-comparator/dump/iri-to-family.json','r'))\n",
    "iri_to_ilx = json.load(open('/home/troy/Desktop/interlexutils/nif-ilx-comparator/dump/iri-to-ilx.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_ilx = makeGraph('', graph=rdflib.Graph().parse('../Interlex.ttl', format='turtle'))\n",
    "#g_ilx = makeGraph('', graph=pickle.load(open('../Interlex.pickle', 'rb')))\n",
    "g_qnames_purpose_only = makeGraph('', graph=rdflib.Graph().parse('../Interlex_qnames.ttl', format='turtle'))\n",
    "g_nif = makeGraph('', graph=pickle.load(open('../NIF-ALL.pickle', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ngraph = makeGraph('', graph=rdflib.Graph().parse('../../work/NIF-Ontology/ttl/bridge/uberon-bridge.ttl', format='turtle'))\\n\\ndef check_restrictions(graph):\\n    r=Restriction(NIFRID.has_proper_part)\\n    pred_passed = set(r.parse(graph=graph.g))\\n\\n    r=Restriction(owl.subClassOf)\\n    sub_passed = set(r.parse(graph=graph.g))\\n\\n    r=Restriction(rdf.first)\\n    list_passed = set(r.parse(graph=graph.g))\\n\\n    return pred_passed & sub_passed & list_passed\\n\\ncheck_restrictions(graph)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check its value aka NIFRID then if it fails, check if the fails are in owl.subClassOf and then rdf.first. If there are still some that fail then look into why it fails \n",
    "#and see if its just a predicate you need to input intead of NIFRID or a different scope\n",
    "'''\n",
    "graph = makeGraph('', graph=rdflib.Graph().parse('../../work/NIF-Ontology/ttl/bridge/uberon-bridge.ttl', format='turtle'))\n",
    "\n",
    "def check_restrictions(graph):\n",
    "    r=Restriction(NIFRID.has_proper_part)\n",
    "    pred_passed = set(r.parse(graph=graph.g))\n",
    "\n",
    "    r=Restriction(owl.subClassOf)\n",
    "    sub_passed = set(r.parse(graph=graph.g))\n",
    "\n",
    "    r=Restriction(rdf.first)\n",
    "    list_passed = set(r.parse(graph=graph.g))\n",
    "\n",
    "    return pred_passed & sub_passed & list_passed\n",
    "\n",
    "check_restrictions(graph)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Delete all Defaults \"\"\"\n",
    "ns_to_del = []\n",
    "for namespace in g_nif.namespaces:\n",
    "    if 'default' in namespace.split(':')[0]:\n",
    "        ns_to_del.append(namespace)\n",
    "for ns in ns_to_del:\n",
    "    g_nif.del_namespace(ns)\n",
    "    \n",
    "\"\"\" Create new namespaces; old are messed up \"\"\"\n",
    "for s, ns in g_nif.namespaces.items():\n",
    "    g_nif.del_namespace(s)\n",
    "    g_nif.add_namespace(s, rdflib.Namespace(str(ns)))\n",
    "\n",
    "\"\"\" Reset blasted cache \"\"\"\n",
    "for _ in range(10):\n",
    "    g_nif.g.namespace_manager.reset()\n",
    "    \n",
    "\"\"\" Fill ilx qname to fix the existing ids \"\"\"\n",
    "for s, ns in g_nif.namespaces.items():\n",
    "    if not g_qnames_purpose_only.namespaces.get(s):\n",
    "        g_qnames_purpose_only.add_namespace(s, rdflib.Namespace(str(ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_cases = {\n",
    "    #Definitions\n",
    "    'definition:' : 'definition:',\n",
    "    'skos:definition' : 'definition:',\n",
    "    'definition' : 'definition:',\n",
    "    'NIFRID:birnlexDefinition' : 'definition:',\n",
    "    'NIFRID:externallySourcedDefinition' : 'definition:',\n",
    "    #ExistingIds\n",
    "    'ilxtr:existingIds' : 'ilxtr:existingIds',  \n",
    "    #LABELS\n",
    "    'rdfs:label' : 'rdfs:label',\n",
    "    'skos:prefLabel' : 'rdfs:label',\n",
    "    #SUPERCLASSES\n",
    "    'rdfs:subClassOf' : 'rdfs:subClassOf',\n",
    "    #SYNONYMS\n",
    "    'oboInOwl:hasExactSynonym' : 'NIFRID:synonym',\n",
    "    #'oboInOwl:hasNarrowSynonym' : 'NIFRID:synonym',\n",
    "    #'oboInOwl:hasBroadSynonym' : 'NIFRID:synonym',\n",
    "    'oboInOwl:hasRelatedSynonym' : 'NIFRID:synonym',\n",
    "    'go:systematic_synonym' : 'NIFRID:synonym',\n",
    "    'NIFRID:synonym' : 'NIFRID:synonym',\n",
    "    #TYPE\n",
    "    'rdf:type':'rdf:type',   \n",
    "}\n",
    "\n",
    "full = {\n",
    "    #'':None,  # safety (now managed directly in the curies file)\n",
    "    #'EHDAA2':'http://purl.obolibrary.org/obo/EHDAA2_',  # FIXME needs to go in curie map?\n",
    "\n",
    "    'hasRole':'http://purl.obolibrary.org/obo/RO_0000087',\n",
    "    'inheresIn':'http://purl.obolibrary.org/obo/RO_0000052',\n",
    "    'bearerOf':'http://purl.obolibrary.org/obo/RO_0000053',\n",
    "    'participatesIn':'http://purl.obolibrary.org/obo/RO_0000056',\n",
    "    'hasParticipant':'http://purl.obolibrary.org/obo/RO_0000057',\n",
    "    'adjacentTo':'http://purl.obolibrary.org/obo/RO_0002220',\n",
    "    'derivesFrom':'http://purl.obolibrary.org/obo/RO_0001000',\n",
    "    'derivesInto':'http://purl.obolibrary.org/obo/RO_0001001',\n",
    "    'agentIn':'http://purl.obolibrary.org/obo/RO_0002217',\n",
    "    'hasAgent':'http://purl.obolibrary.org/obo/RO_0002218',\n",
    "    'containedIn':'http://purl.obolibrary.org/obo/RO_0001018',\n",
    "    'contains':'http://purl.obolibrary.org/obo/RO_0001019',\n",
    "    'locatedIn':'http://purl.obolibrary.org/obo/RO_0001025',\n",
    "    'locationOf':'http://purl.obolibrary.org/obo/RO_0001015',\n",
    "    'toward':'http://purl.obolibrary.org/obo/RO_0002503',\n",
    "\n",
    "    'replacedBy':'http://purl.obolibrary.org/obo/IAO_0100001',\n",
    "    'hasCurStatus':'http://purl.obolibrary.org/obo/IAO_0000114',\n",
    "    'definition':'http://purl.obolibrary.org/obo/IAO_0000115',\n",
    "    'editorNote':'http://purl.obolibrary.org/obo/IAO_0000116',\n",
    "    'termEditor':'http://purl.obolibrary.org/obo/IAO_0000117',\n",
    "    'altTerm':'http://purl.obolibrary.org/obo/IAO_0000118',\n",
    "    'defSource':'http://purl.obolibrary.org/obo/IAO_0000119',\n",
    "    'termsMerged':'http://purl.obolibrary.org/obo/IAO_0000227',\n",
    "    'obsReason':'http://purl.obolibrary.org/obo/IAO_0000231',\n",
    "    'curatorNote':'http://purl.obolibrary.org/obo/IAO_0000232',\n",
    "    'importedFrom':'http://purl.obolibrary.org/obo/IAO_0000412',\n",
    "\n",
    "    'partOf':'http://purl.obolibrary.org/obo/BFO_0000050',\n",
    "    'hasPart':'http://purl.obolibrary.org/obo/BFO_0000051',\n",
    "}\n",
    "\n",
    "normal = {\n",
    "    'ILX':'http://uri.interlex.org/base/ilx_',\n",
    "    'ilx':'http://uri.interlex.org/base/',\n",
    "    'ilxr':'http://uri.interlex.org/base/readable/',\n",
    "    'ilxtr':'http://uri.interlex.org/tgbugs/uris/readable/',\n",
    "    # for obo files with 'fake' namespaces, http://uri.interlex.org/fakeobo/uris/ eqiv to purl.obolibrary.org/\n",
    "    'fobo':'http://uri.interlex.org/fakeobo/uris/obo/',\n",
    "\n",
    "    'PROTEGE':'http://protege.stanford.edu/plugins/owl/protege#',\n",
    "    'ILXREPLACE':'http://ILXREPLACE.org/',\n",
    "    'TEMP': interlex_namespace('temp/uris'),\n",
    "    'FIXME':'http://FIXME.org/',\n",
    "    'NIFTTL':'http://ontology.neuinfo.org/NIF/ttl/',\n",
    "    'NIFRET':'http://ontology.neuinfo.org/NIF/Retired/NIF-Retired.owl#',\n",
    "    'NLXWIKI':'http://neurolex.org/wiki/',\n",
    "    'dc':'http://purl.org/dc/elements/1.1/',\n",
    "    'dcterms':'http://purl.org/dc/terms/',\n",
    "    'dctypes':'http://purl.org/dc/dcmitype/',  # FIXME there is no agreement on qnames\n",
    "    # FIXME a thought: was # intentionally used to increase user privacy? or is this just happenstance?\n",
    "    'nsu':'http://www.FIXME.org/nsupper#',\n",
    "    'oboInOwl':'http://www.geneontology.org/formats/oboInOwl#',\n",
    "    'owl':'http://www.w3.org/2002/07/owl#',\n",
    "    'ro':'http://www.obofoundry.org/ro/ro.owl#',\n",
    "    'skos':'http://www.w3.org/2004/02/skos/core#',\n",
    "    'rdf':'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "    'rdfs':'http://www.w3.org/2000/01/rdf-schema#',\n",
    "    'prov':'http://www.w3.org/ns/prov#',\n",
    "}\n",
    "\n",
    "expo = {\n",
    "    'ilxtr:existingId':'ilxtr:identifier',\n",
    "    'oboInOwl:hasAlternativeId':'ilxtr:identifier',\n",
    "    'NIFRID:isReplacedByClass':'replacedBy:',\n",
    "    'skos:editorialNote' : 'editorNote:',\n",
    "    'ncbitaxon:has_rank' : 'NIFRID:hasTaxonRank',\n",
    "}\n",
    "#Maybe a 5th category which is \"labels/synonyms with parens in them\" \n",
    "#would be a way to see whether that is a good filter would help too.\n",
    "\n",
    "#extras = {**full, **normal}\n",
    "extras = full\n",
    "\n",
    "qilx = g_ilx.qname\n",
    "qnif = g_nif.qname\n",
    "#qnif = g_ilx.qname\n",
    "qall = g_qnames_purpose_only.qname\n",
    "\n",
    "edge_cases = {**{qnif(v):k+':' for k,v in extras.items()}, **edge_cases, **expo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/troy/Desktop/interlexutils/ontology-interlex/dump/moderate-nif-ilx-comparator-extras.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf2417738f6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0moutf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/troy/Desktop/interlexutils/ontology-interlex/dump/moderate-nif-ilx-comparator-extras.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/troy/Desktop/interlexutils/ontology-interlex/dump/moderate-nif-ilx-comparator-extras.json'"
     ]
    }
   ],
   "source": [
    "interlex_with_mods = defaultdict(set)\n",
    "nif_with_mods = defaultdict(set)\n",
    "\n",
    "#changed to list to have a ranking system within the data to make it more complicated with bloat data.\n",
    "rank_list = []\n",
    "data = defaultdict(list)\n",
    "def rank(pad, rank_list):\n",
    "    if not rank_list: return pad\n",
    "    score = []\n",
    "    rank_list = rank_list[::-1]\n",
    "    for item in pad:\n",
    "        if item in rank_list:\n",
    "            score.append((rank_list.index(item), item))\n",
    "        else:\n",
    "            score.append((-1, item))\n",
    "    return [v[1] for v in sorted(score)[::-1]]\n",
    "\n",
    "for subj in g_ilx.g.subjects(rdflib.RDF.type, rdflib.OWL.Class):\n",
    "    \n",
    "    #if qilx(subj) != 'ILX:0102930': continue\n",
    "    \n",
    "    shared_iris = set()\n",
    "    ilx_mod_conversion = {}\n",
    "    nif_mod_conversion = {}\n",
    "    \n",
    "    for pred, obj in g_ilx.g.predicate_objects(subject=subj):\n",
    "        \n",
    "        '''Needs traversal convert superclass ilx to its respected exisiting ids'''\n",
    "        if qilx(pred) == 'rdfs:subClassOf': \n",
    "            superclasses_iris = iri_to_family_iris[str(obj)]\n",
    "            for superclasses_iri in superclasses_iris:\n",
    "                tup = (qilx(pred), ' '.join(superclasses_iri.lower().strip().split()))\n",
    "                ilx_mod_conversion[tup] = (qilx(pred), superclasses_iri)\n",
    "                interlex_with_mods[qilx(subj)].add(tup)    \n",
    "        else:        \n",
    "            tup = (qnif(pred), ' '.join(str(obj).lower().strip().split()))\n",
    "            ilx_mod_conversion[tup] = (qilx(pred), str(obj))\n",
    "            interlex_with_mods[qilx(subj)].add(tup)\n",
    "        \n",
    "        '''Build nif when ilx exisiting id found in nif'''\n",
    "        if qilx(pred) == 'ilxtr:existingIds':\n",
    "            for p, o in g_nif.g.predicate_objects(subject=obj): \n",
    "                shared_iris.add(obj)\n",
    "                tup = (qnif(p), ' '.join(str(o).lower().strip().split()))\n",
    "                if edge_cases.get(qnif(p)):\n",
    "                    nif_with_mods[qnif(obj)].add((edge_cases[tup[0]], tup[1]))\n",
    "                    nif_mod_conversion[(edge_cases[tup[0]], tup[1])] = (qnif(p), str(o))\n",
    "                else:\n",
    "                    nif_with_mods[qnif(obj)].add(tup)\n",
    "                    nif_mod_conversion[tup] = (qnif(p), str(o))\n",
    "                    \n",
    "    '''Comparator btw current ilx term and each nif term sharing ilx existing id'''      \n",
    "    for shared_iri in rank(shared_iris, rank_list):\n",
    "        #print(shared_iris)\n",
    "        nif = nif_with_mods[qnif(shared_iri)]\n",
    "        ilx = interlex_with_mods[qilx(subj)]\n",
    "        \n",
    "        i = ilx - nif\n",
    "        n = nif - ilx\n",
    "        b = nif & ilx\n",
    "        \n",
    "        def formatter(current_set, mod_conversion):\n",
    "            return sorted([(p,(o)) for p,o in [mod_conversion[po] for po in current_set]])\n",
    "        \n",
    "        data[qall(subj)].append({\n",
    "            qall(shared_iri): {\n",
    "                'ilx_only'     : formatter(i, ilx_mod_conversion),\n",
    "                'nif_only'     : formatter(n, nif_mod_conversion),\n",
    "                'both_contain' : formatter(b, nif_mod_conversion),\n",
    "            }\n",
    "        })    \n",
    "\n",
    "outf = '/home/troy/Desktop/interlexutils/ontology-interlex/dump/moderate-nif-ilx-comparator-extras.json'\n",
    "with open(outf, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4)\n",
    "    \n",
    "#ex for short hand vi -e \n",
    "#-s so it doesnt print file details\n",
    "#-cwq is command-save-quit\n",
    "#use $ to specify variable\n",
    "!ex -s +'g/\\[[\\ \\n]\\+\"/j4' -cwq $outf\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.w3.org/2000/01/rdf-schema#label identifier resolution\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://www.w3.org/2002/07/owl#Class\n",
      "http://www.w3.org/2000/01/rdf-schema#subClassOf http://uri.neuinfo.org/nif/nifstd/nlx_res_20090416\n"
     ]
    }
   ],
   "source": [
    "for pred, obj in g_nif.g.predicate_objects(subject=rdflib.term.URIRef('http://uri.neuinfo.org/nif/nifstd/nlx_157906')):\n",
    "    print(pred, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparator_data = json.load(open('dump/moderate-nif-ilx-comparator-extras.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cv(string):\n",
    "    return ' '.join(string.lower().strip().split())\n",
    "\n",
    "hits = set()\n",
    "new_comparator_data = comparator_data.copy()\n",
    "count_per_id = 0\n",
    "count_per_element = 0\n",
    "\n",
    "for ilx_identifer, shared_iris in comparator_data.items():\n",
    "    for i, shared_iri in enumerate(shared_iris):\n",
    "        for iri, inb in shared_iri.items():\n",
    "            expo = {'same':[], 'different':[]}\n",
    "            for ilx_pred, ilx_obj in inb['ilx_only']:\n",
    "                for nif_pred, nif_obj in inb['nif_only']:\n",
    "                    \n",
    "                    ''' diff logic here '''\n",
    "                    for test in [r'definition', r'synonym', r'label']: #for each test case given; keeps noise out\n",
    "                        if re.search(test, cv(ilx_pred)) and re.search(test, cv(nif_pred)): #and nif_pred != 'skos:definition':\n",
    "                            if cv(ilx_obj) == cv(nif_obj):\n",
    "                                count_per_element += 1\n",
    "                                expo['same'].append([(test, nif_pred), nif_obj])\n",
    "                                print(test, ilx_pred, nif_pred)\n",
    "                            else:\n",
    "                                expo['different'].append([(test, nif_pred), [ilx_obj, nif_obj]])\n",
    "            \n",
    "            if expo: count_per_id += 1\n",
    "            #print(expo)\n",
    "            new_comparator_data[ilx_identifer][i][iri]['experimental'] = expo #[(),(),()]\n",
    "\n",
    "outf = 'dump/expo-moderate-nif-ilx-comparator-extras2.json'\n",
    "with open(outf, 'w') as outfile:\n",
    "    json.dump(new_comparator_data, outfile, indent=4)\n",
    "!ex -s +'g/\\[[\\ \\n]\\+\"/j4' -cwq $outf\n",
    "print(count_per_id)\n",
    "print(count_per_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['key']) dict_values(['value'])\n"
     ]
    }
   ],
   "source": [
    "a={'key':'value'}\n",
    "key, value = a.keys(), a.values()\n",
    "print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random possible equals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILX:0106722\n",
    "rdfs:subClassOf == oboInOwl:id \n",
    "\n",
    "ILX:0104473\n",
    "definition: == dc:description \n",
    "\n",
    "ILX:0101393\n",
    "NIFRID:synonym == NIFRID:taxonomicCommonName \n",
    "\n",
    "ILX:0101464\n",
    "definition:\n",
    "NIFRID:externallySourcedDefinition\n",
    "\n",
    "ILX:0102938\n",
    "definition: A solubility which is relatively low.\n",
    "obo:IAO_0000115 A solubility which is relatively low. \n",
    "\n",
    "ILX:0104395\n",
    "rdfs:subClassOf PATO:0001444\n",
    "obo:IAO_0100001 PATO:0001444 \n",
    "\n",
    "ILX:0109258\n",
    "definition: == obo:UBPROP_0000001 \n",
    "\n",
    "ILX:0108780\n",
    "rdfs:label PH-sensitive electrode recording protocol\n",
    "skos:prefLabel pH-sensitive electrode recording protocol\n",
    "\n",
    "ILX:0109341\n",
    "rdfs:label Primate\n",
    "skos:altLabel primate \n",
    "\n",
    "ILX:0101385\n",
    "rdfs:subClassOf NCBITaxon:7089\n",
    "oboInOwl:id NCBITaxon:7089 \n",
    "\n",
    "ILX:0101527\n",
    "rdfs:subClassOf == NIFRID:hasFormerParentClass \n",
    "\n",
    "ILX:0111998\n",
    "rdfs:subClassOf == owl:equivalentClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    " \n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    " \n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    "\n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score, count = 0.0, 0\n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "            \n",
    "        best_score=[synset.path_similarity(ss) for ss in synsets2 if synset.path_similarity(ss)]\n",
    "    \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score:\n",
    "            score += max(best_score)\n",
    "            count += 1\n",
    "    \n",
    "    # Average the values\n",
    "    if count > 0:\n",
    "        score /= count\n",
    "    else:\n",
    "        score = 0\n",
    "\n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
